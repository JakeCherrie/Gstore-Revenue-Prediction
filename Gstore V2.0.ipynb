{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Analytics Customer Revenue Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File system manangement\n",
    "import os\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Numpy and pandas for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 300)\n",
    "# Importing random for random selections\n",
    "import random\n",
    "# Json for importing JSON columns\n",
    "import json as json\n",
    "# Pandas io json normalizing\n",
    "from pandas.io.json import json_normalize\n",
    "# Scipy stats for statistical analysis\n",
    "import scipy.stats as stats\n",
    "# Datetime for handelling datetime variables\n",
    "import datetime as dt\n",
    "# sklearn preprocessing for dealing with categorical features\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# to use for woe binning for features with a large number of categories\n",
    "import scorecardpy as sc\n",
    "# Light gradient boost classifier\n",
    "from lightgbm import LGBMRegressor\n",
    "# Sklearn Inputing data spliting method\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\n",
    "# Sklearn importing auc as measurement metric\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Gc memory managment\n",
    "import gc\n",
    "# Matplotlib pyplot for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "# Seabourne for visualization\n",
    "import seaborn as sns\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Setting up package to import data converting JSON columns into individual features\n",
    "# # https://www.kaggle.com/julian3833/1-quick-start-read-csv-and-flatten-json-fields\n",
    "# JSON_COLUMNS = ['device', 'geoNetwork', 'totals', 'trafficSource']\n",
    "# def load_df(csv_path):\n",
    "#     df = pd.read_csv(csv_path, converters={column: json.loads for column in JSON_COLUMNS}\\\n",
    "#                      , dtype={'fullVisitorId': 'str', 'visitStartTime': 'str', 'date': 'str'})\n",
    "#     for column in JSON_COLUMNS:\n",
    "#         column_as_df = json_normalize(df[column])\n",
    "#         column_as_df.columns = [f\"{column}.{subcolumn}\" for subcolumn in column_as_df.columns]\n",
    "#         df = df.drop(column, axis=1).merge(column_as_df, right_index=True, left_index=True)\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bins sets',\n",
       " 'sample_submission.csv',\n",
       " 'test.csv',\n",
       " 'train.csv',\n",
       " 'trn.csv',\n",
       " 'trn_tgt.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seeting the input and output directory\n",
    "os.chdir('C:/Users/Jake Cherrie/Documents/Projects/Gstore Revenue Prediction')\n",
    "# Viewing the contained datasets\n",
    "os.listdir('C:/Users/Jake Cherrie/Data Sets/Gstore Revenue Prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Importing the training data\n",
    "# trn_df = load_df('C:/Users/Jake Cherrie/Data Sets/Gstore Revenue Prediction/train.csv')\n",
    "# trn_df['totals.transactionRevenue'].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Droping features with no information\n",
    "# drp_cols = [col for col in trn_df.columns if trn_df[col].nunique() == 1 & trn_df[col].notnull().values.all()]\n",
    "# trn_df = trn_df.drop(columns=drp_cols)\n",
    "# # Dropping duplicate feature visitStartTime is the same as visitId\n",
    "# trn_df = trn_df.drop(columns='visitId')\n",
    "# # Dropping capaign code as there is ony 1 non-null entry\n",
    "# trn_df = trn_df.drop(columns='trafficSource.campaignCode')\n",
    "# # Noticed that for the training set channelGrouping contains all the information in trafficSource.medium so droping trafficSource.medium\n",
    "# trn_df = trn_df.drop(columns='trafficSource.medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Saving memory by shortning ints and floats\n",
    "# def size_reduction(df):\n",
    "#     int_col     = df.select_dtypes(include=[np.int64]).columns\n",
    "#     flt_col     = df.select_dtypes(include=[np.float64]).columns \n",
    "#     df[int_col] = df[int_col].astype(np.int32)\n",
    "#     df[flt_col] = df[flt_col].astype(np.float32)  \n",
    "# size_reduction(trn_df)\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trn_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing the testing data\n",
    "# tst_df = load_df('C:/Users/Jake Cherrie/Data Sets/Gstore Revenue Prediction/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Quick view of training data\n",
    "# tst_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Droping features with no information\n",
    "# drp_cols = [col for col in tst_df.columns if tst_df[col].nunique() == 1 & tst_df[col].notnull().values.all()]\n",
    "# tst_df = tst_df.drop(columns=drp_cols)\n",
    "# # Dropping duplicate feature visitStartTime is the same as visitId\n",
    "# tst_df = tst_df.drop(columns='visitId')\n",
    "# tst_df = tst_df.drop(columns='trafficSource.medium')\n",
    "\n",
    "# size_reduction(tst_df)\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tst_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reformating the data for the new problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Setting the index as fullVisitorId\n",
    "# trn.set_index('fullVisitorId', inplace=True)\n",
    "# tst.set_index('fullVisitorId', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Looking at first and last shows that it is clearly a time dependent problem\n",
    "# trn['visitStartTime'] = pd.to_datetime(trn['visitStartTime'],unit='s')\n",
    "# print(trn['visitStartTime'].describe())\n",
    "# tst['visitStartTime'] = pd.to_datetime(tst['visitStartTime'],unit='s')\n",
    "# print(tst['visitStartTime'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating training set\n",
    "# trn_df = trn[trn['visitStartTime'] < (trn['visitStartTime'].max() - dt.timedelta(62))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating target values\n",
    "# tgt_mths = trn[trn['visitStartTime'] > (trn['visitStartTime'].max() - dt.timedelta(62))]\n",
    "# tgt_values = np.log1p(tgt_mths.groupby('fullVisitorId').sum()['totals.transactionRevenue'])\n",
    "# # Creating target dataframe\n",
    "# trn_tgt = pd.DataFrame(index=pd.Series(trn_df.index.values), columns=['targetLogRevenue'])\n",
    "# # Maping taget values to the dataframe\n",
    "# trn_tgt['targetLogRevenue'] = trn_tgt.index.to_series().map(tgt_values)\n",
    "# trn_tgt.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Data for Quick Loads and Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trn_df.to_csv('C:/Users/Jake Cherrie/Data Sets/Gstore Revenue Prediction/trn.csv', index=False)\n",
    "# trn_tgt.to_csv('C:/Users/Jake Cherrie/Data Sets/Gstore Revenue Prediction/trn_tgt.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn = pd.read_csv('C:/Users/Jake Cherrie/Data Sets/Gstore Revenue Prediction/trn.csv'\\\n",
    "           , dtype={'fullVisitorId': 'str', 'visitStartTime': 'str', 'date': 'str'}, nrows=None)\n",
    "trn_tgt = pd.read_csv('C:/Users/Jake Cherrie/Data Sets/Gstore Revenue Prediction/trn_tgt.csv', nrows=None)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tst' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-af31c1d76c2b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdbg_trn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m300000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdbg_tst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m200000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mtrn_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdbg_trn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mtst_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdbg_tst\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tst' is not defined"
     ]
    }
   ],
   "source": [
    "# Setting up debugging datasets\n",
    "random.seed(42)\n",
    "dbg_trn = random.sample(list(pd.Series(trn.index.values).unique()),300000)\n",
    "dbg_tst = random.sample(list(pd.Series(tst.index.values).unique()),200000)\n",
    "trn_df = trn.loc[dbg_trn]\n",
    "tst_df = tst.loc[dbg_tst]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Time Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_df['weekday'] = trn_df['visitStartTime'].dt.weekday.astype(str)\n",
    "tst_df['weekday'] = tst_df['visitStartTime'].dt.weekday.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_df['time']  = trn_df['visitStartTime'].dt.hour.astype(str)\n",
    "tst_df['time']  = tst_df['visitStartTime'].dt.hour.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting dataframes by visitStartTime\n",
    "trn_df.sort_values(['visitStartTime'], inplace=True)\n",
    "trn_df.sort_values(['visitStartTime'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time since last and till next session\n",
    "def sessions(df):\n",
    "    df['timePrevSession'] = (\n",
    "            df.groupby('fullVisitorId')['visitStartTime'].shift(1) - df['visitStartTime']\n",
    "        ).astype(np.int64)//1e9//60//60\n",
    "    df['timeNextSession'] = (\n",
    "            df['visitStartTime'] - df.groupby('fullVisitorId')['visitStartTime'].shift(-1)\n",
    "        ).astype(np.int64)//1e9//60//60\n",
    "sessions(trn_df)\n",
    "sessions(tst_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of visits\n",
    "trn_df['totalVisits'] = trn_df.groupby('fullVisitorId')['visitNumber'].max()\n",
    "tst_df['totalVisits'] = tst_df.groupby('fullVisitorId')['visitNumber'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratio of visits\n",
    "trn_df['ratioVisits'] = trn_df['visitNumber']/trn_df['totalVisits']\n",
    "tst_df['ratioVisits'] = tst_df['visitNumber']/tst_df['totalVisits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of visits for each Visitor\n",
    "def visitList(df):\n",
    "    vst_df = df['visitStartTime']\n",
    "    # Maximum number of entries\n",
    "    num = df.groupby('fullVisitorId')['visitStartTime'].count().max()\n",
    "    for i in range(1,num):\n",
    "        vst_df['visit_'+str(i)] = df.groupby('fullVisitorId')['visitStartTime'].shift(i)\n",
    "    return vst_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of visits for each Visitor\n",
    "def visitList(df):\n",
    "    vst_lst = df.groupby('fullVisitorId')['visitStartTime']\\\n",
    "                .apply(lambda df: list(df))\\\n",
    "                .apply(lambda x: {'visit_'+str(i): visit for i, visit in enumerate(sorted(x))})\n",
    "    vst_df = pd.DataFrame(index=pd.Series(df.index.values).unique(),data=list(vst_lst.values))\n",
    "    return vst_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_df.groupby('fullVisitorId')['visitStartTime'].count().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_vst = visitList(trn_df)\n",
    "tst_vst = visitList(tst_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn['visitStartTime'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the simple bins to the data frame\n",
    "def deviceBrowser(x):\n",
    "    if x in ['Chrome', 'Safari', 'Firefox', 'Safari (in-app)', 'Amazon Silk', 'Opera', 'Android Webview']:\n",
    "        return x\n",
    "    elif x in ['Internet Explorer', 'Edge']:\n",
    "        return 'Microsoft Browser'\n",
    "    else:\n",
    "        return 'Other'\n",
    "trn_df['device.browser'] = trn_df['device.browser'].map(lambda x:deviceBrowser(x))\n",
    "tst_df['device.browser'] = tst_df['device.browser'].map(lambda x:deviceBrowser(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trn_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-66b1382213d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;34m'Other'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mtrn_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'device.operatingSystem'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrn_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'device.operatingSystem'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mdeviceOperatingSystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mtst_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'device.operatingSystem'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtst_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'device.operatingSystem'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mdeviceOperatingSystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trn_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Applying the simple bins to the data frame\n",
    "def deviceOperatingSystem(x):\n",
    "    if x in ['Android', 'Chrome OS', 'Linux', 'Macintosh', 'Windows', 'iOS', '(not set)', 'Samsung']:\n",
    "        return x\n",
    "    elif x in ['BlackBerry', 'Windows Phone']:\n",
    "        return 'Other Phone'\n",
    "    elif x in ['Xbox', 'Playstation Vita', 'Nintendo WiiU', 'Nintendo 3DS']:\n",
    "        return 'Gaming'\n",
    "    else:\n",
    "        return 'Other'\n",
    "trn_df['device.operatingSystem'] = trn_df['device.operatingSystem'].map(lambda x:deviceOperatingSystem(x))\n",
    "tst_df['device.operatingSystem'] = tst_df['device.operatingSystem'].map(lambda x:deviceOperatingSystem(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trn_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-299ff21fc0cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;34m'Other'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mtrn_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'trafficSource.adContent'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrn_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'trafficSource.adContent'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtrafficSourceAdContent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mtst_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'trafficSource.adContent'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtst_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'trafficSource.adContent'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtrafficSourceAdContent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trn_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Applying the simple bins to the data frame\n",
    "def trafficSourceAdContent(x):\n",
    "    if pd.isnull(x):\n",
    "        return 'NA'\n",
    "    elif 'Google' in x:\n",
    "        return 'google'\n",
    "    elif 'Ad' in x.lower():\n",
    "        return 'Ad'\n",
    "    elif 'discount' in x:\n",
    "        return 'Discount'\n",
    "    else:\n",
    "        return 'Other'\n",
    "trn_df['trafficSource.adContent'] = trn_df['trafficSource.adContent'].map(lambda x:trafficSourceAdContent(x))\n",
    "tst_df['trafficSource.adContent'] = tst_df['trafficSource.adContent'].map(lambda x:trafficSourceAdContent(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trn_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-61c53d105f44>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;34m'Other'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mtrn_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'trafficSource.campaign'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrn_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'trafficSource.campaign'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtrafficSourceCampaign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mtst_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'trafficSource.campaign'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtst_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'trafficSource.campaign'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtrafficSourceCampaign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trn_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Applying groups (makes the cv worse)\n",
    "def trafficSourceCampaign(x):\n",
    "    if '(not set)' in x:\n",
    "        return '(not set)'\n",
    "    elif 'AW' in x:\n",
    "        return 'AW'\n",
    "    elif 'Data Share Promo' in x:\n",
    "        return 'Data Share Promo'\n",
    "    elif ('google+redesign' in x) or ('google + redesign' in x):\n",
    "        return 'redesign'\n",
    "    else:\n",
    "        return 'Other'\n",
    "trn_df['trafficSource.campaign'] = trn_df['trafficSource.campaign'].map(lambda x:trafficSourceCampaign(x))\n",
    "tst_df['trafficSource.campaign'] = tst_df['trafficSource.campaign'].map(lambda x:trafficSourceCampaign(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trn_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-d964c20b4dee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;34m'Other'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mtrn_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'trafficSource.keyword'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrn_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'trafficSource.keyword'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtrafficSourceKeyword\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mtst_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'trafficSource.keyword'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtst_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'trafficSource.keyword'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtrafficSourceKeyword\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trn_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Applying bins (makes it worse then none...)\n",
    "def trafficSourceKeyword(x):\n",
    "    if pd.isnull(x):\n",
    "        return 'NA'\n",
    "    elif '6qehscssdk0z36ri' in x:\n",
    "        return '???'\n",
    "    elif '(not provided)' in x:\n",
    "        return '(not provided)'\n",
    "    elif (('google' in x) and ('merchandise' in x)) or (('google' in x) and ('merch' in x))\\\n",
    "      or (('google' in x) and ('stickers' in x))    or (('google' in x) and ('shirt' in x))\\\n",
    "      or (('google' in x) and ('swag' in x))        or (('google' in x) and ('gear' in x))\\\n",
    "      or (('google' in x) and ('accessories' in x)):\n",
    "        return 'Google Merch'\n",
    "    else:\n",
    "        return 'Other'\n",
    "trn_df['trafficSource.keyword'] = trn_df['trafficSource.keyword'].map(lambda x:trafficSourceKeyword(str(x).lower()))\n",
    "tst_df['trafficSource.keyword'] = tst_df['trafficSource.keyword'].map(lambda x:trafficSourceKeyword(str(x).lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trn_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-f02df3235139>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;34m'Other'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mtrn_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'trafficSource.source'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrn_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'trafficSource.source'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtrafficSourceSource\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mtst_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'trafficSource.source'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtst_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'trafficSource.source'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtrafficSourceSource\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trn_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Applying bins (makes it worse then none...)\n",
    "def trafficSourceSource(x):\n",
    "    if x in ['google', 'mall.googleplex.com', '(direct)', 'dfa', 'dealspotr.com']:\n",
    "        return x\n",
    "    elif x in ['youtube.com', 'Partners']:\n",
    "        return 'Partners'\n",
    "    elif 'google' in str(x).lower():\n",
    "        return 'Other Google'\n",
    "    else:\n",
    "        return 'Other'\n",
    "trn_df['trafficSource.source'] = trn_df['trafficSource.source'].map(lambda x:trafficSourceSource(x))\n",
    "tst_df['trafficSource.source'] = tst_df['trafficSource.source'].map(lambda x:trafficSourceSource(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating New Combination Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trn_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-d5f2df5e0229>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Setting up a has revenue flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrn_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'hasRevenue'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrn_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'totals.transactionRevenue'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtrn_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'logRevenue'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog1p\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrn_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'totals.transactionRevenue'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trn_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Setting up a has revenue flag\n",
    "trn_df['hasRevenue'] = (trn_df['totals.transactionRevenue'] > 0).astype(int)\n",
    "trn_df['logRevenue'] = np.log1p(trn_df['totals.transactionRevenue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_df['trafficSource.keyword'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = trn_df[trn_df['totals.transactionRevenue'] > 0].groupby('trafficSource.keyword')['trafficSource.keyword'].unique().index.values\n",
    "sns.barplot(y='trafficSource.keyword', x='logRevenue', data=trn_df[trn_df['trafficSource.keyword'].isin(cols)])\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ploting count per group\n",
    "sns.countplot(y='trafficSource.keyword', data=trn_df[trn_df['trafficSource.keyword'].isin(cols)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the weekday relationship to the log1p revenue\n",
    "sns.barplot('weekday', 'logRevenue', data = trn_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ploting count per group\n",
    "sns.countplot('weekday', data=trn_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight of Evidence (WOE) encoding\n",
    "weekday = trn_df[['weekday','hasRevenue']]\n",
    "#bins_weekday = sc.woebin(weekday, y='hasRevenue', stop_limit=0.02, max_num_bin=2, method='tree')\n",
    "#Saving for quick load    \n",
    "#np.save('C:/Users/Jake Cherrie/Data Sets/Gstore Revenue Prediction/Bins sets/bins_weekday.npy', bins_weekday) \n",
    "# Quick load of dataframe\n",
    "bins_weekday = np.load('C:/Users/Jake Cherrie/Data Sets/Gstore Revenue Prediction/Bins sets/bins_weekday.npy').item()\n",
    "bins_weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying WOE encoding\n",
    "#trn_df['weekday'] = sc.woebin_ply(trn_df, bins_weekday)['weekday_woe']\n",
    "#tst_df['weekday'] = sc.woebin_ply(tst_df, bins_weekday)['weekday_woe']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and encoding feature and target datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping unused features\n",
    "trn_set = trn_df.drop(columns=['visitStartTime', 'date', 'sessionId', 'trafficSource.adwordsClickInfo.gclId'])\n",
    "tst_set = tst_df.drop(columns=['visitStartTime', 'date', 'sessionId', 'trafficSource.adwordsClickInfo.gclId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating feature and target sets\n",
    "trn_fts = trn_set[tst_set.columns]\n",
    "trn_tgt = trn_set['logRevenue']\n",
    "tst_fts = tst_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_fts.shape, tst_fts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up categorical columns\n",
    "cat_col = [col for col in trn_fts.columns if trn_fts[col].dtype == 'object']\n",
    "# factorizing categorical columns\n",
    "for col in cat_col:\n",
    "    indexer = pd.factorize(trn_set[col])[1]\n",
    "    trn_fts[col] = indexer.get_indexer(trn_fts[col])\n",
    "    tst_fts[col] = indexer.get_indexer(tst_fts[col])\n",
    "# Converting bool into int\n",
    "trn_fts['device.isMobile'] = trn_fts['device.isMobile'].astype(int)\n",
    "tst_fts['device.isMobile'] = tst_fts['device.isMobile'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visit ID Level Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing lgb paramaters\n",
    "params={'num_leaves': 31,\n",
    "        'max_depth': 16,\n",
    "        'learning_rate': 0.03,\n",
    "        'n_estimators': 1000,\n",
    "        'metric':'rmse',\n",
    "        'num_leaves': 31,\n",
    "        'verbose': 1,\n",
    "        \"subsample\": 0.9,\n",
    "        \"colsample_bytree\": 0.9,\n",
    "        \"random_state\":42,\n",
    "        'min_child_samples': 20\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unq_vis = np.array(sorted(pd.Series(trn_df.index.values).unique()))\n",
    "# Get folds\n",
    "Kflds = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "flds = []\n",
    "for trn_, vld in Kflds.split(X=unq_vis, y=unq_vis):\n",
    "    flds.append([unq_vis[trn_],unq_vis[vld]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing Variables\n",
    "trn_df['prd'] = 0\n",
    "trn_prd =  trn_df['prd']\n",
    "tst_prd = np.zeros(tst_fts.shape[0])\n",
    "imp = pd.DataFrame()\n",
    "wgt_sum = 0\n",
    "MSE = 0\n",
    "\n",
    "for n_fld ,(trn_idx, vld_idx) in enumerate(flds):\n",
    "    #trn_idx = idx_tab.iloc[trn_num].index\n",
    "    #vld_idx = idx_tab.iloc[vld_num].index\n",
    "    trn_X, trn_y = trn_fts.loc[trn_idx], trn_tgt.loc[trn_idx]\n",
    "    vld_X, vld_y = trn_fts.loc[vld_idx], trn_tgt.loc[vld_idx]\n",
    "    \n",
    "    lgb = LGBMRegressor(**params)\n",
    "    \n",
    "    # Fit the model\n",
    "    lgb.fit(trn_X, trn_y)\n",
    "    \n",
    "    # applying the model to the validation data\n",
    "    val_prd = lgb.predict(vld_X)\n",
    "    val_prd[val_prd < 0] = 0\n",
    "    # Calculating and outputting the RMSE\n",
    "    fld_MSE = mean_squared_error(vld_y, val_prd)\n",
    "    print('Fold %2d RMSE : %.6f' % (n_fld + 1, np.sqrt(fld_MSE)))\n",
    "    \n",
    "    # Summing mean squared errors\n",
    "    MSE += fld_MSE/5\n",
    "    wgt_sum += 1/np.sqrt(fld_MSE)\n",
    "    \n",
    "    # Applying predictions to the train set weighted by the MSE\n",
    "    prd = lgb.predict(vld_X)\n",
    "    prd[prd < 0] = 0\n",
    "    trn_prd.loc[vld_idx] = prd\n",
    "    \n",
    "    # Applying predictions to the test set weighted by the MSE\n",
    "    prd = lgb.predict(tst_fts)\n",
    "    prd[prd < 0] = 0\n",
    "    tst_prd += prd/np.sqrt(fld_MSE)\n",
    "    \n",
    "    # Calculating the fold importance\n",
    "    imp_df = pd.DataFrame()\n",
    "    imp_df['fts'] = trn_X.columns\n",
    "    imp_df['imp'] = lgb.booster_.feature_importance(importance_type='gain')\n",
    "    \n",
    "    # Summing the fold importances\n",
    "    imp_df['fld'] = n_fld+1\n",
    "    imp = pd.concat([imp, imp_df], axis=0, sort=False)\n",
    "\n",
    "np.sqrt(MSE)\n",
    "# full = 1.6336474922884041\n",
    "# 1.6387851689243524\n",
    "# 1.6377402085589046"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling and assigning the predictions\n",
    "trn_fts['prd'] = np.expm1(trn_prd)\n",
    "trn_fts['log_prd'] = trn_prd\n",
    "tst_fts['prd'] = np.expm1(tst_prd/wgt_sum)\n",
    "tst_fts['log_prd'] = tst_prd/wgt_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ploting stage 1 feature importances\n",
    "cols = imp[[\"fts\", \"imp\"]].groupby(\"fts\").mean().sort_values(by=\"imp\", ascending=False)[:60].index\n",
    "imp['log1p_imp'] = np.log1p(imp['imp'])\n",
    "best_features = imp.loc[imp.fts.isin(cols)]\n",
    "plt.figure(figsize=(8, 12))\n",
    "sns.barplot(x=\"log1p_imp\", y=\"fts\", data=best_features.sort_values(by=\"imp\", ascending=False))\n",
    "plt.title('Features (avg over folds)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of predictions for each Visitor\n",
    "def prediction_list(df):\n",
    "    prd_lst = df.groupby('fullVisitorId')['log_prd']\\\n",
    "                .apply(lambda df: list(df))\\\n",
    "                .apply(lambda x: {'pred_'+str(i): pred for i, pred in enumerate(x[:10])})\n",
    "    return pd.DataFrame(index=pd.Series(df.index.values).unique(),data=list(prd_lst.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features: Perform aggregations\n",
    "aggregations = {\n",
    "    'channelGrouping': ['median'],\n",
    "    'visitNumber': ['max', 'sum'],\n",
    "    'device.browser': ['median'],\n",
    "    'device.deviceCategory': ['median'], \n",
    "    'device.isMobile': ['max', 'sum', 'min'], \n",
    "    'device.operatingSystem': ['median'],\n",
    "    'geoNetwork.city': ['median'], \n",
    "    'geoNetwork.continent': ['median'], \n",
    "    'geoNetwork.country': ['median'],\n",
    "    'geoNetwork.metro': ['median'], \n",
    "    'geoNetwork.networkDomain': ['median'], \n",
    "    'geoNetwork.region': ['median'],\n",
    "    'geoNetwork.subContinent': ['median'], \n",
    "    'totals.bounces': ['max','sum'], \n",
    "    'totals.hits': ['max'],\n",
    "    'totals.newVisits': ['max'], \n",
    "    'totals.pageviews': ['max'], \n",
    "    'trafficSource.adContent': ['median'],\n",
    "    'trafficSource.adwordsClickInfo.adNetworkType': ['median'],\n",
    "    #'trafficSource.adwordsClickInfo.gclId': ['median'],\n",
    "    'trafficSource.adwordsClickInfo.isVideoAd': ['median'],\n",
    "    'trafficSource.adwordsClickInfo.page': ['median'],\n",
    "    'trafficSource.adwordsClickInfo.slot': ['median'], \n",
    "    'trafficSource.campaign': ['median'],\n",
    "    'trafficSource.isTrueDirect': ['median'], \n",
    "    'trafficSource.keyword': ['median'],\n",
    "    'trafficSource.referralPath': ['median'], \n",
    "    'trafficSource.source': ['median'],\n",
    "    'log_prd': ['sum','max'],\n",
    "    'prd': ['sum','max'],\n",
    "    'prev_session': ['mean', 'sum'],\n",
    "    'next_session': ['mean', 'sum']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_agg = trn_fts.groupby('fullVisitorId').agg(aggregations)\n",
    "trn_agg.columns = pd.Index([e[0] + \".\" + e[1].upper() for e in trn_agg.columns.tolist()])\n",
    "tst_agg = tst_fts.groupby('fullVisitorId').agg(aggregations)\n",
    "tst_agg.columns = pd.Index([e[0] + \".\" + e[1].upper() for e in tst_agg.columns.tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding visit prediction\n",
    "#trn_agg = pd.concat([trn_agg, prediction_list(trn_fts)], axis=1)\n",
    "#size_reduction(trn_agg)\n",
    "#tst_agg = pd.concat([tst_agg, prediction_list(tst_fts)], axis=1)\n",
    "#size_reduction(tst_agg)\n",
    "#trn_agg = trn_agg[tst_agg.columns]\n",
    "#gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_agg['prd.SUM'] = np.log1p(trn_agg['prd.SUM'])\n",
    "tst_agg['prd.SUM'] = np.log1p(tst_agg['prd.SUM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_agg = np.log1p(trn_df.groupby('fullVisitorId').sum()['totals.transactionRevenue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_agg.shape, tst_agg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing stage 2 paramaters\n",
    "params={'num_leaves': 31,\n",
    "        'max_depth': 15,\n",
    "        'learning_rate': 0.03,\n",
    "        'n_estimators': 1200,\n",
    "        'num_leaves': 31,\n",
    "        'verbose': 100,\n",
    "        \"subsample\": 0.9,\n",
    "        \"colsample_bytree\": 0.9,\n",
    "        \"random_state\":42,\n",
    "        'lambda_l2': 0.02085548700474218,\n",
    "        'lambda_l1': 0.004107624022751344,\n",
    "        'bagging_fraction': 0.7934712636944741,\n",
    "        'feature_fraction': 0.686612409641711\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing Variables\n",
    "sub_prd = np.zeros(tst_agg.shape[0])\n",
    "imp = pd.DataFrame()\n",
    "wgt_sum  = 0\n",
    "MSE = 0\n",
    "\n",
    "for n_fld, (trn_idx, vld_idx) in enumerate(flds):\n",
    "    #trn_idx = idx_tab.iloc[trn_num].index\n",
    "    #vld_idx = idx_tab.iloc[vld_num].index\n",
    "    trn_X, trn_y = trn_agg.loc[trn_idx], tgt_agg.loc[trn_idx]\n",
    "    vld_X, vld_y = trn_agg.loc[vld_idx], tgt_agg.loc[vld_idx]\n",
    "\n",
    "    lgb = LGBMRegressor(**params)\n",
    "    \n",
    "    # Fit the model\n",
    "    lgb.fit(trn_X, trn_y)\n",
    "    \n",
    "    # applying the model to the validation data\n",
    "    vld_prd = lgb.predict(vld_X)\n",
    "    vld_prd[vld_prd < 0] = 0\n",
    "    # Calculating and outputting the RMSE\n",
    "    fld_MSE = mean_squared_error(vld_y, vld_prd)\n",
    "    print('Fold %2d RMSE : %.6f' % (n_fld + 1, np.sqrt(fld_MSE)))\n",
    "    \n",
    "    # Summing mean squared errors\n",
    "    MSE += fld_MSE/5\n",
    "    wgt_sum += 1/np.sqrt(fld_MSE) \n",
    "    \n",
    "    # Applying predictions\n",
    "    prd = lgb.predict(tst_agg)\n",
    "    prd[prd < 0] = 0\n",
    "    sub_prd += prd/np.sqrt(fld_MSE)\n",
    "    \n",
    "    # Calculating the fold importance\n",
    "    imp_df = pd.DataFrame()\n",
    "    imp_df['fts'] = trn_X.columns\n",
    "    imp_df['imp'] = lgb.booster_.feature_importance(importance_type='gain')\n",
    "    \n",
    "    # Summing the fold importances\n",
    "    imp_df['fld'] = n_fld+1\n",
    "    imp = pd.concat([imp, imp_df], axis=0, sort=False)\n",
    "\n",
    "np.sqrt(MSE)\n",
    "# Full = 1.5992181821979747 LB = 1.4378\n",
    "# Full = 1.5990424003087966 LB = 1.4295"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ploting stage 2 feature importances\n",
    "cols = imp[[\"fts\", \"imp\"]].groupby(\"fts\").mean().sort_values(by=\"imp\", ascending=False)[:80].index\n",
    "imp['log1p_imp'] = np.log1p(imp['imp'])\n",
    "best_features = imp.loc[imp.fts.isin(cols)]\n",
    "plt.figure(figsize=(8, 14))\n",
    "sns.barplot(x=\"log1p_imp\", y=\"fts\", data=best_features.sort_values(by=\"imp\", ascending=False))\n",
    "plt.title('Features (avg over folds)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_agg['predictedLogRevenue'] = sub_prd/wgt_sum\n",
    "tst_agg['predictedLogRevenue'].to_csv('submission.csv', header = True, index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
